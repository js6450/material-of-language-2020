# #coronavirus: a visual poetry

[See the project live!](https://tweet-py.herokuapp.com/) You may have to wait a couple of seconds to see the tweet visualizations to appear.

[![project screenshot](media/coronavirus-poem.png)](https://www.youtube.com/watch?v=9H2Z-3bM0PQ&feature=youtu.be)
[Video documentation of the project is also available.](https://www.youtube.com/watch?v=9H2Z-3bM0PQ&feature=youtu.be)

## Technical Details

This project uses [Tweepy](https://www.tweepy.org/) to stream recent tweets filtered by #coronavirus and uses [TextBlob](https://textblob.readthedocs.io/en/dev/index.html) for sentiment analysis to generate the visualizations of the tweets. 3 to 4 tweets are displayed at a given time, and new tweets are continuously retrieved for new visualizations.

The size of the text and the amount of sideways movement depend on how subjective the tweet is. Tweets with positive sentiments travel towards the top, and those with negative sentiments move towards the bottom. If sentiment of a tweet is very negative (score of less than -0.5) then there is added noise to the generated visualization, making the tweets less readable.

The server is written in python with [Flask](https://flask.palletsprojects.com/en/1.1.x/) and uses [socket.io](https://socket.io/) to pass on data (points of the font data for text, raw tweet text, sentiment analysis score) to the web client. Text visualizations are generated by extracting points of font data of the text of the tweets using [Bezmerizing](https://github.com/aparrish/bezmerizing).

To run the code yourself, download the files in the ```final``` folder of this repository and create a conda virtual environment. Then run ``` pip install -r requirements.txt ``` and run ```python server.py``` or ```gunicorn server:app``` to start the python server.

## Motivations

Coronavirus (COVID-19) has been the central topic of discussion since early 2020 and has drastically changed our lives. Browsing through Twitter for the latest updates of the situation has highlighted the fact that the top tweets that appear at the top or the most popular retweets often have political motives. Rarely do individuals' tweets appear as the popular tweets when searching through Twitter and I wanted to create an artistic experiment by visualizing recent tweets filtered by #coronavirus and generate them by mapping the subjectiveness and polarity (positive and negative sentiment) of the tweet to various elements of the visualizations.

## Process

### Getting Twitter Stream

For [assignment 4](http://jiwonshin.com/mol/week4/), I had created a jupyter notebook that collected tweets with #coronavirus filter to generate a webpage of concrete poetry in the shape the virus' cellular structure. 

![coronavirus concrete poetry](media/coronavirus-concrete.png)

Every time the webpage is generated, the tweets are updated, but the webpage itself doesn't continuously retrieve data. For the final project, I wanted to create a website that streamed the tweets and re-render the visualization with the new tweets. 

I found this [dataquest tutorial](https://www.dataquest.io/blog/streaming-data-python/) that combines [Tweepy](https://www.tweepy.org/) and [TextBlob](https://textblob.readthedocs.io/en/dev/index.html) to stream tweets a helpful reference point, as [the Tweepy documentation on streaming](http://docs.tweepy.org/en/latest/streaming_how_to.html) quite rudimentary. 

```
tweets = []
lastsent = 0
interval = 3

class MyStreamListener(tweepy.StreamListener):
    def on_status(self, status):
        # print("retrieving tweets")
        if len(tweets) > 3:
            tweets.pop(0)
        if hasattr(status, "retweeted_status"):  # Check if Retweet
            try:
                newtweet = status.retweeted_status.extended_tweet["full_text"]
                if detect(newtweet) == 'en':
                    # print(re.sub("http\S+", "", newtweet))
                    tweets.append([re.sub("http\S+", "", newtweet), generate_path(re.sub("http\S+", "", newtweet), TextBlob(newtweet).sentiment[1]), TextBlob(newtweet).sentiment])
            except AttributeError:
                pass
        else:
            try:
                newtweet = status.extended_tweet["full_text"]
                if detect(newtweet) == 'en':
                    # print(re.sub("http\S+", "", newtweet))
                    tweets.append([re.sub("http\S+", "", newtweet), generate_path(re.sub("http\S+", "", newtweet), TextBlob(newtweet).sentiment[1]), TextBlob(newtweet).sentiment])
            except AttributeError:
                pass
        global lastsent
        if int(time.time()) > lastsent + interval:
            socketio.emit('tweet-data', {'data': tweets})
            lastsent = int(time.time())

    def on_error(self, status_code):
        if status_code == 420:
            return False

listener = MyStreamListener()
stream = tweepy.Stream(auth=api.auth, listener=listener)
stream.filter(track=['coronavirus'], is_async=True)
```

The stream listener of [Tweepy](https://www.tweepy.org/) is event based and ```on_status``` event gets triggered when tweets filtered by #coronavirus is received. When tweets are received, I had process tweets separately depending on whether it was an original tweet or a retweet, because retweets' ```full_text``` element was truncated. Simple regex command to get rid of any URLs in the tweets are also applied before sending the tweets to the client side for visualization.

### Sentiment Analysis with TextBlob

When tweets are received, I had to check whether the text was in English due to the fact that TextBlob's sentiment analysis is trained on movie review data in English. Inputing text of languages other than English will return subjectivity and polarity values of 0.

The subjectivity score of the each tweet is also being used in the generating the coordinates of the font data of the tweet to decide the size of the text.

### Hosting on Web

In order the host the project online, I first looked at using Glitch, but due to the memory and disk space constraints, I could not host my project there. I ended up using [heroku](https://heroku.com) which allowed more freedom with memory and space constraints but also caused some more work to reshape the code to make it runnable on the server. One of the issue was installing the NLTK data (dependancy of TextBlob) on the heroku server, and I found [a very helpful answer](https://github.com/sloria/TextBlob/issues/59#issuecomment-162663570) in the TextBlob github issues, and followed the instructions in the comment, which worked like a charm.

### Generating Visualizations

The received coordinate data for each tweet visualizes the text in one single line. In order to have the text wrap written a certain width, I made changes to the coordinates by adding and subtracting x and y offsets.

```
this.xoffset = 0;
this.yoffset = 0;

for(let i = 0; i < this.points.length; i++){
    if(this.points[i][0] - this.xoffset > this.width){
        this.yoffset += 20;
        this.xoffset += this.width;
    }

    this.points[i][0] = this.points[i][0] - this.xoffset;
    this.points[i][1] = this.points[i][1] + this.yoffset;
}
```

This, when rendered as lines, created lines that connect the last point of the row to the first point of the next row. I decided to leave this in the final version, as it added to the visual effect of written text / scribble in a notebook.

## Observations

The simple black and white aesthetics of the text visualizations highlight the differences in how each of the texts are rendered. I had initially thought about incorporating color into the piece, but found the result to be too noisy / messy. 

The results of sentiment analysis through [TextBlob](https://textblob.readthedocs.io/en/dev/index.html) were not necessarily how people would generally assess them. For example, if the tweet has the word "positive" (in the context of "my mother tested positive") the resulting sentiment would be positive when a person reading the tweet would argue that it is not. Thus, the work has an added layer of how a machine learned algorithm would assess people's sentiment and that is being reflected as visualizations of the tweets.

## Thoughts about Future Iteration

This project as multiple layers of messages and metaphors. The intent was to see what the TextBlob sentiment analysis thought of the tweets about coronavirus as well as to see what the differences in the visual representations reveal. With some more observation of the generated visualizations, it would be worthwhile to fine tune the method of visualizing these tweets to create a more uniform / central theme. 

For technical improvement, I would like to experiment with different methods of visualizing the font data, as it is currently drawing approximately 3000 - 5000 lines per tweet and is computationally heavy. I would like to find a solution that allows me to dynamically animate the visualized text as well as improve the efficiency of the drawing.
